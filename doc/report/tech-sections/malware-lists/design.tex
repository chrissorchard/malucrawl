\subsection{Design}
Malware list scanners are a type of Zero Interaction Malware Scanner.

The scanners use a collection of URLs or domain names that are pre-generated and made available by other systems such as WOT, Alexa and the Google Safe Browsing APIs, this means that these scanners do not interact in any way with the target server that is being investigated, ie they do not download the page content. This is an advantage both because potentially less web requests have to be made and importantly the target server cannot detect this type of scan.

\subsubsection{Services}
Alexa is a service that maintains a list of domains ranked by traffic. This traffic rank is determined ``by analyzing the Web usage of millions of Alexa Toolbar users and data obtained from other, diverse traffic data sources.''\cite{alexa-about}. This list is available as a zipped CSV that is updated daily \verb`http://s3.amazonaws.com/alexa-static/top-1m.csv.zip`.

To use the Alexa service the data in the the CSV must be made available, locally, to all of the worker nodes. A web request should not be made more than once per day to the Alexa service as this is a waste of bandwidth. As such a distributed database, with the ability to designate a master and many slaves must be used.

WOT makes available a JSON API endpoint \verb`http://api.mywot.com/0.4/public_link_json` for querying a database of domains associated with values of ``Trustworthiness'', ``Vendor reliability'', ``Privacy'' and ``Child Safety''. Because the system is only intersted in potential malware only the ``Trustworthiness'' value is taken into account.

These values are crowd sourced: ``Based on ratings from millions of web users and trusted technical sources''\cite{wot-about}.

The API endpoint has a single (non JSONP) parameter; ``hosts''. Instead of accepting multiple values for parameter as is usual in HTTP server implementations - to match select multiple fields, for example: \verb`?host=example.COM&host=www.EXAMPLE.NET`, the WOT api requires each value to be delimited with `/' and the entire collection of values to be terminated with a trailing `/': \verb`?hosts=example.COM/www.EXAMPLE.NET/.../`.

The usage limits of the API are as follows\cite{wot-about}:

\begin{itemize}
    \item The API must only be called once every 10 minutes.
    \item A request for the same domain must not be made in any 30 minute interval.
    \item The number of domains in the HTTP request must not exceed 100.
    \item The size of the URL of the HTTP request must not exceed 8KiB.
\end{itemize}

To prevent exceeding the usage limit, WOT tasks that access the database must be batched and results should be cached across the entire distributed system with a timeout of 30 minutes.

\nomenclature{CSV}{Comma Separated Values file}
\nomenclature{WOT}{Web of Trust}
\nomenclature{JSON}{JavaScript Object Notation}
\nomenclature{JSONP}{JSON with padding}

\subsection{Implementation}
\subsubsection{Tools}
\paragraph{Redis}
Both systems require a distributed storage component that can allow any worker to edit data in a centralized manner while also being able to access that data locally. The system chosen for this was Redis\cite{redis} because Redis is already being used as part of Celery, it supports a distributed mode of operation and transactions.

Redis allows us to designate a write master and many read slaves. This master should be placed in some location all the worker nodes can access, and can in fact be distributed across multiple machines.  In the \emph{Prototype Deployment} one node was arbitrarily chosen to be this master. All the workers also have a slave set to mirror off of the master Redis instance.

\subsubsection{Alexa Specifics}
The Alexa scanning system is split into two Celery Tasks, \emph{update\_alexa} a task to be run by a daily Celery Beat Periodic Task and \emph{alexa\_malware\_scan} a regular Celery Task to be called by the crawling system.

The daily task \emph{alexa\_top\_million} downloads the zipped CSV file of the top million domains, extracts the contained CSV file into memory. This CSV file is parsed row-wise using the CSV DictReader from the Python standard library. Finally, in a single transaction to the master Redis database, the previous value stored is deleted and a new Redis Hash value is created from the domain -> rank mappings in the CSV. This transaction ensures that there is no point at which no data is stored in any of the slaves after the initial sync-up.

\subsubsection{WOT Specifics}
The Celery \verb`celery.contrib.batches` decorator is part of the celery API that allows multiple invocations of a single task to be buffered in a queue and executed at once with the entire collection of Celery Task request contexts made available at once. These request contexts are passed an as argument to the decorated function. This functionality is required because the WOT API allows multiple domains to be requested at once.

The WOT scanning system uses as a single Celery batches task \emph{wot\_malware\_scan}, backed by a regular Python function \emph{wot\_malware\_scan\_real}.

The batching task is configured to be run once 100 single tasks have been buffered or when 10 seconds have elapsed, this then passes an iterable collection of URLs to \emph{wot\_malware\_scan\_real}. \emph{wot\_malware\_scan\_real} returns an iterable of responses, in the same order as the URLs were requested. The batching task \emph{wot\_malware\_scan} then marks each single task request context as done, with the corresponding return value from \emph{wot\_malware\_scan\_real}\cite{celery-batches}.

The Batching task documentation did not describe how to return any results, as such this functionality had to be researched from some of the internal parts of the Celery library.  This research was written up and submitted to be included in the Celery documentation as a GitHub GitHub Pull Request and accepted\cite{celery-batches-fix}.

\paragraph{Redis Cache Abstraction}
The Redis cache system is used to prevent the workers requesting the same data from the WOT API too often.  This was implemented using a caching function that can be used elsewhere in the project, abstracting away the caching layer.  The \emph{redis\_cache} function takes a \verb`key_prefix` to prevent collisions, a \verb`prepare` and \verb`request` function, and finally the set of \verb`items` that need to be requested.

The \verb`prepare` function is used to process each item into the required part, for example parsing the domain out of a URL.

The unique prepared items are requested from the local slave Redis database, and added to the total response. The request function is then applied to the collection of cache\_misses, updating the total response.

Finally each item discovered in the request phase is added to the remote Redis write master and the total response is returned.

\paragraph{Usage of the Redis Cache Abstraction}
The \emph{wot\_malware\_scan\_real} invokes the Redis abstraction function with the following arguments:
\begin{itemize}
    \item \verb`key_prefix` ``malucrawl:web\_api:wot:{item}''
    \item \verb`prepare` function that takes a URL and returns the host-name part
    \item \verb`request` function that, to meet the further requirements of the API guidelines, splits the domains into buckets limited to 8KiB and dispatches them separately.
\end{itemize}

\subsection{Testing}
\subsubsection{Alexa}
The Alexa malware scanning system is very quick to test: there are no necessary buffer delays or complex caching systems. Each individual Task simply results in a single lookup in a local Redis instance, and there is no change from debug operation to full system operation.

\subsubsection{WOT}
\paragraph{Celery Batch Processing with Eventlet}
When the WOT Batch process task was executed for the first time using the Eventlet threading model the Celery debug log very quickly filled up with exceptions from the Eventlet and Celery libraries:

\begin{verbatim}
Traceback (most recent call last):
    File "/.../eventlet/greenpool.py", line 80, in _spawn_n_impl
        func(*args, **kwargs)
    File "/.../celery/concurrency/eventlet.py", line 50, in apply_target
        pid=getpid())
    File "/.../celery/concurrency/base.py", line 27, in apply_target
        callback(target(*args, **kwargs))
    TypeError: 'NoneType' object is not callable
\end{verbatim}

While these exceptions did not occur under the multiprocessing threading model, hinting that the problem might not be with the system code but in fact part of the Celery library itself.

The issue was determined to be part of the Batches API in which the Eventlet Green Thread Pool task was called with a NoneType callback, instead of a do nothing noop function.  This defect did not affect multiprocessing threads because a multiprocessing thread pool checks for a NoneType callback.

\verb`callback=acks_late[True] and on_return or None)`
became
\verb`callback=acks_late[True] and on_return or noop)`

Where noop is part of the standard ``utils'' available in the Celery library.

This change was delivered to the upstream community as a GitHub Pull Request and accepted\cite{celery-batches-fix}.

\paragraph{Debug Mode}
The Web Of Trust testing system when using a ten second delay before the Batches Task buffer is forcibly executed without waiting for 100 Tasks would be very slow thus making it difficult to make a change and verify if that change was correct. As such to prevent a stilted work-flow the delay is set to 0.1 seconds while the system is in debug mode (Controlled by a flag set in the Django settings file).  Meaning that the buffer is effectively emptied as soon as a single Task is requested.
\paragraph{Redis Caching Layer}
As part of the full system test, it was determined that Web Of Trust malware analyzer was returning results unrelated to the URLs it was being called with.

The offending line was tracked down to:

\verb`return [total_response[item] for items in item]`

Where \verb`item` is the last \verb`item` left in scope after one of the previous python \verb`for` loops, that requested each item from or inserted each item into the cache.

This typo caused the data returned from the caching layer to only be relevant to a single item, meaning the bug is undetectable when only a single task has been buffered. Hence why it was only discovered after a complete integration test with the rest of the system.

% * into/malware type
% * APIs used
%     * WOT
%     * Alexa
% * Alexa
%     * celery beat ZIP download
% * WOT
%     * API requirements
%     * batch process, return items
%     * URL < 8Kio, <100